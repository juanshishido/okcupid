{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 1,
>>>>>>> master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from string import punctuation\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "import pickle \n",
    "import numpy as np\n",
    "\n",
    "from utils import *"
=======
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "import warnings\n",
    "from string import punctuation\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from utils.calculate_pmi_features import get_data, tokenize_words\n",
    "\n",
    "warnings.filterwarnings('ignore')"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 2,
>>>>>>> master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "#Checking whether 'w not in stopwords.words('english') takes FOREVER. So I converted it to a dictionary\n",
    "#because checking whether or not w is in a list of size n takes O(n) time, but looking something up in\n",
    "#a dictionary takes O(1) time.\n",
    "stop_dict = {}\n",
    "for w in stopwords.words('english'):\n",
    "    stop_dict[w] = 1\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    df = pd.read_csv('data/profiles.20120630.csv')\n",
    "    #print(df.columns.values )\n",
    "    def remove_nan(s):\n",
    "        if type(s) == float:\n",
    "            return ''\n",
    "        return s\n",
    "    \n",
    "    #dealing with the nan values of essays\n",
    "    essays = df.columns.values[7:17]\n",
    "    for text in essays:\n",
    "        df[text] = df[text].apply(remove_nan)\n",
    "    df['TotalEssays'] = df[essays].apply(lambda x: ' '.join(x), axis=1)\n",
    "    df['TotalEssays'] = df['TotalEssays'].apply(lambda x: BeautifulSoup(x).getText().replace('\\n', ' '))\\\n",
    "                                            .apply(lambda x: re.sub('\\s+', ' ', x).strip())\n",
    "    return df[df.TotalEssays.str.len() > 0]\n",
    "\n",
    "\n",
    "#Tokenizes the concatenated essay using the hft\n",
    "def tokenize_words(df):\n",
    "    tokenizer = Tokenizer()\n",
    "    df['TotalEssayTokens'] = df['TotalEssays'].apply(lambda x: tokenizer.tokenize(x))\n",
    "    return df\n",
    "\n",
    "\n",
=======
    "stop_dict = {}\n",
    "for w in stopwords.words('english'):\n",
    "    stop_dict[w] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is different than what's in `calculate_pmi_features.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
>>>>>>> master
    "def generate_freqdists(df, stop_dict):\n",
    "    words = df['TotalEssayTokens'].tolist()\n",
    "    words = [item for sublist in words for item in sublist]\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
<<<<<<< HEAD
    "    words = [wordnet_lemmatizer.lemmatize(w.lower()) for w in words if w not in string.punctuation]\n",
=======
    "    words = [wordnet_lemmatizer.lemmatize(w.lower())\n",
    "             for w in words\n",
    "             if w not in string.punctuation]\n",
>>>>>>> master
    "\n",
    "    #ngrams keep stopwords, unigrams remove them\n",
    "    ngrams = nltk.ngrams(words, 4)\n",
    "    ngram_freq = nltk.FreqDist(ngrams)\n",
    "    \n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
<<<<<<< HEAD
    "    words = [wordnet_lemmatizer.lemmatize(w.lower()) for w in words if w not in string.punctuation and w.lower() not in stop_dict]\n",
=======
    "    words = [wordnet_lemmatizer.lemmatize(w.lower())\n",
    "             for w in words\n",
    "             if w not in string.punctuation and w.lower() not in stop_dict]\n",
>>>>>>> master
    "    unigram_freq = nltk.FreqDist(words)\n",
    "    \n",
    "    \n",
    "    return unigram_freq, ngram_freq"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 4,
>>>>>>> master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categories_from_hypernyms(termlist, num_cats=20, num_terms=50):\n",
    "\n",
    "    hypterms = []\n",
    "    hypterms_dict = defaultdict(list)\n",
    "    for term in termlist:                  # for each term\n",
<<<<<<< HEAD
    "        s = wn.synsets(term.lower())  # get its nominal synsets\n",
=======
    "        s = wn.synsets(term.lower())       # get its nominal synsets\n",
>>>>>>> master
    "        for syn in s:                      # for each lemma synset\n",
    "            for hyp in syn.hypernyms():    # It has a list of hypernyms\n",
    "                hypterms = hypterms + [hyp.name()]      # Extract the hypernym name and add to list\n",
    "                hypterms_dict[hyp.name()].append(term)  # Extract examples and add them to dict\n",
    "\n",
    "    hypfd = nltk.FreqDist(hypterms)\n",
    "\n",
<<<<<<< HEAD
    "    return hypfd, hypterms_dict\n"
=======
    "    return hypfd, hypterms_dict"
>>>>>>> master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 5,
>>>>>>> master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "km_dict = pickle.load(open(\"data/km_dict.pkl\", \"rb\" ))\n",
    "df_main = get_data()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 6,
>>>>>>> master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_main = tokenize_words(df_main)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 7,
>>>>>>> master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_freq, ngram_freq = generate_freqdists(df_main, stop_dict)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 8,
>>>>>>> master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "termlist = [word[0] for word in unigram_freq.most_common(1000)] "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 9,
>>>>>>> master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hypfd, hypterms_dict = categories_from_hypernyms(termlist)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 10,
>>>>>>> master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = ngram_freq.most_common(1000) "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 11,
>>>>>>> master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build dataframe with example ngrams for each category and their counts\n",
    "example_dict = defaultdict(list)\n",
    "df_all = pd.DataFrame()\n",
    "words = []\n",
    "for (name, count) in hypfd.most_common(20):\n",
    "    examples = []\n",
    "    words = []\n",
    "    counts = []\n",
    "    for f in fd:\n",
    "        for x in hypterms_dict[name]:\n",
    "            if x in f[0]: #if the term is in a frequently occuring ngram\n",
    "                words.append(x)\n",
    "                examples.append(f[0])\n",
    "                counts.append(f[1])\n",
    "                example_dict[x].append(f)\n",
    "\n",
    "    df = pd.DataFrame([words, examples, counts]).transpose()\n",
    "    df.columns = ['word','example','count']\n",
    "    df_all = df_all.append(df)\n",
    "    \n",
    "#filter dataframe to keep only frequent ngrams\n",
    "df_all = df_all.groupby(['word','example']).sum()\n",
    "df_all = df_all[df_all['count']>20]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 12,
>>>>>>> master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th>example</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <th>(a, fair, amount, of)</th>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask</th>\n",
       "      <th>(feel, free, to, ask)</th>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">back</th>\n",
       "      <th>(back, to, the, bay)</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(back, to, the, future)</th>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(get, back, to, you)</th>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(go, back, to, school)</th>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(going, back, to, school)</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(just, got, back, from)</th>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(moved, back, to, the)</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(to, get, back, into)</th>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(to, go, back, to)</th>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bang</th>\n",
       "      <th>(the, big, bang, theory)</th>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">best</th>\n",
       "      <th>(do, my, best, to)</th>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(one, of, the, best)</th>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(the, best, way, to)</th>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(to, be, the, best)</th>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">better</th>\n",
       "      <th>(be, a, better, person)</th>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(the, world, a, better)</th>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(to, be, a, better)</th>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(to, know, me, better)</th>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(world, a, better, place)</th>\n",
       "      <td>1482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">born</th>\n",
       "      <th>(born, and, raised, in)</th>\n",
       "      <td>3104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, wa, born, and)</th>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, wa, born, in)</th>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(wa, born, and, raised)</th>\n",
       "      <td>1774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <th>(to, change, the, world)</th>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>child</th>\n",
       "      <th>(city, of, lost, child)</th>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">come</th>\n",
       "      <th>(it, come, to, food)</th>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(that, come, to, mind)</th>\n",
       "      <td>2781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(when, it, come, to)</th>\n",
       "      <td>20754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">watch</th>\n",
<<<<<<< HEAD
       "      <th>(i, don't, watch, much)</th>\n",
       "      <td>307</td>\n",
=======
       "      <th>(i, don't, watch, tv)</th>\n",
       "      <td>254</td>\n",
>>>>>>> master
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, like, to, watch)</th>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, watch, a, lot)</th>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(watch, a, lot, of)</th>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(www, youtube, com, watch)</th>\n",
       "      <td>1520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(youtube, com, watch, v)</th>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <th>(after, a, long, week)</th>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekend</th>\n",
       "      <th>(on, the, weekend, i)</th>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went</th>\n",
       "      <th>(went, to, college, in)</th>\n",
       "      <td>3223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">work</th>\n",
       "      <th>(a, work, in, progress)</th>\n",
<<<<<<< HEAD
       "      <td>4050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, a, a)</th>\n",
       "      <td>6880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, a, lot)</th>\n",
       "      <td>2870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, at, a)</th>\n",
       "      <td>6520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, for, a)</th>\n",
       "      <td>6560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, full, time)</th>\n",
       "      <td>2670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, hard, and)</th>\n",
       "      <td>3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, in, the)</th>\n",
       "      <td>5750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(work, hard, play, hard)</th>\n",
       "      <td>2610</td>\n",
=======
       "      <td>3645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, a, a)</th>\n",
       "      <td>6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, a, lot)</th>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, at, a)</th>\n",
       "      <td>5868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, for, a)</th>\n",
       "      <td>5904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, full, time)</th>\n",
       "      <td>2403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, hard, and)</th>\n",
       "      <td>2745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, work, in, the)</th>\n",
       "      <td>5175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(work, hard, play, hard)</th>\n",
       "      <td>2349</td>\n",
>>>>>>> master
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">working</th>\n",
       "      <th>(i, am, currently, working)</th>\n",
<<<<<<< HEAD
       "      <td>3573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, am, working, on)</th>\n",
       "      <td>3852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(when, i'm, not, working)</th>\n",
       "      <td>4113</td>\n",
=======
       "      <td>3176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, am, working, on)</th>\n",
       "      <td>3424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(when, i'm, not, working)</th>\n",
       "      <td>3656</td>\n",
>>>>>>> master
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">year</th>\n",
       "      <th>(100, year, of, solitude)</th>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(a, couple, of, year)</th>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(a, few, year, ago)</th>\n",
       "      <td>1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(for, a, few, year)</th>\n",
       "      <td>1506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(hundred, year, of, solitude)</th>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(one, hundred, year, of)</th>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(the, last, few, year)</th>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(the, past, few, year)</th>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(year, and, a, half)</th>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       count\n",
       "word    example                             \n",
       "amount  (a, fair, amount, of)            310\n",
       "ask     (feel, free, to, ask)            355\n",
       "back    (back, to, the, bay)             390\n",
       "        (back, to, the, future)          668\n",
       "        (get, back, to, you)             298\n",
       "        (go, back, to, school)           426\n",
       "        (going, back, to, school)        432\n",
       "        (just, got, back, from)          271\n",
       "        (moved, back, to, the)           364\n",
       "        (to, get, back, into)            320\n",
       "        (to, go, back, to)               485\n",
       "bang    (the, big, bang, theory)         554\n",
       "best    (do, my, best, to)               315\n",
       "        (one, of, the, best)             438\n",
       "        (the, best, way, to)             447\n",
       "        (to, be, the, best)              266\n",
       "better  (be, a, better, person)          726\n",
       "        (the, world, a, better)         1338\n",
       "        (to, be, a, better)              986\n",
       "        (to, know, me, better)          1052\n",
       "        (world, a, better, place)       1482\n",
       "born    (born, and, raised, in)         3104\n",
       "        (i, wa, born, and)              1786\n",
       "        (i, wa, born, in)               1510\n",
       "        (wa, born, and, raised)         1774\n",
       "change  (to, change, the, world)         574\n",
       "child   (city, of, lost, child)          262\n",
       "come    (it, come, to, food)            2439\n",
       "        (that, come, to, mind)          2781\n",
       "        (when, it, come, to)           20754\n",
       "...                                      ...\n",
<<<<<<< HEAD
       "watch   (i, don't, watch, much)          307\n",
=======
       "watch   (i, don't, watch, tv)            254\n",
>>>>>>> master
       "        (i, like, to, watch)             306\n",
       "        (i, watch, a, lot)               292\n",
       "        (watch, a, lot, of)              619\n",
       "        (www, youtube, com, watch)      1520\n",
       "        (youtube, com, watch, v)        1507\n",
       "week    (after, a, long, week)           856\n",
       "weekend (on, the, weekend, i)            314\n",
       "went    (went, to, college, in)         3223\n",
<<<<<<< HEAD
       "work    (a, work, in, progress)         4050\n",
       "        (i, work, a, a)                 6880\n",
       "        (i, work, a, lot)               2870\n",
       "        (i, work, at, a)                6520\n",
       "        (i, work, for, a)               6560\n",
       "        (i, work, full, time)           2670\n",
       "        (i, work, hard, and)            3050\n",
       "        (i, work, in, the)              5750\n",
       "        (work, hard, play, hard)        2610\n",
       "working (i, am, currently, working)     3573\n",
       "        (i, am, working, on)            3852\n",
       "        (when, i'm, not, working)       4113\n",
=======
       "work    (a, work, in, progress)         3645\n",
       "        (i, work, a, a)                 6192\n",
       "        (i, work, a, lot)               2583\n",
       "        (i, work, at, a)                5868\n",
       "        (i, work, for, a)               5904\n",
       "        (i, work, full, time)           2403\n",
       "        (i, work, hard, and)            2745\n",
       "        (i, work, in, the)              5175\n",
       "        (work, hard, play, hard)        2349\n",
       "working (i, am, currently, working)     3176\n",
       "        (i, am, working, on)            3424\n",
       "        (when, i'm, not, working)       3656\n",
>>>>>>> master
       "year    (100, year, of, solitude)        837\n",
       "        (a, couple, of, year)            948\n",
       "        (a, few, year, ago)             1443\n",
       "        (for, a, few, year)             1506\n",
       "        (hundred, year, of, solitude)    975\n",
       "        (one, hundred, year, of)         873\n",
       "        (the, last, few, year)           969\n",
       "        (the, past, few, year)           942\n",
       "        (year, and, a, half)             780\n",
       "\n",
       "[640 rows x 1 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 18,
=======
     "execution_count": 12,
>>>>>>> master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.3.5"
=======
   "version": "3.4.2"
>>>>>>> master
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
